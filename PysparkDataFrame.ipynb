{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507f3fec",
   "metadata": {},
   "source": [
    "### Create DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32db96",
   "metadata": {},
   "source": [
    "### Create DataFrame From RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "62846134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d25b1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a96b52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('dataframe').master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9ea19a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DOT595I:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=dataframe>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b8ccf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = spark.sparkContext.textFile(\"C:/Users/W10/Desktop/sparkTxt/onemillion.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1c8ae963",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "                            .map(lambda word: (word, 1)) \\\n",
    "                           .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9f882fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hi', 1),\n",
       " ('i', 1),\n",
       " ('am', 1),\n",
       " ('prathmesh', 1),\n",
       " ('futane', 1),\n",
       " ('trying', 1),\n",
       " ('to', 1),\n",
       " ('learn', 1),\n",
       " ('apache', 2),\n",
       " ('spark.', 1),\n",
       " ('spark', 1),\n",
       " ('is', 1),\n",
       " ('good', 1),\n",
       " ('big', 1),\n",
       " ('data', 1),\n",
       " ('processing', 1),\n",
       " ('framework.', 1)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f07c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using toDF() function\n",
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b031f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbac109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fcac88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef000ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using createDataFrame function\n",
    "rdd1 = spark.createDataFrame(data).toDF(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3467b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0bf13c",
   "metadata": {},
   "source": [
    "### Create DataFrame from list collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62425780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spark session\n",
    "rdd2 = spark.createDataFrame([('1','jack'),('2','mack')],['serial_no', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "174a39ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|serial_no|name|\n",
      "+---------+----+\n",
      "|        1|jack|\n",
      "|        2|mack|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bcf8dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with RowType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2cfa432",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3506a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# createDataFrame with schema\n",
    "schema = StructType([\n",
    "    StructField('firstname', StringType(), True),\n",
    "    StructField('lastname', StringType(), True),\n",
    "    StructField(\"lastname\",StringType(),True), \n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True), \n",
    "    StructField(\"salary\", IntegerType(), True) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d4b49ec",
   "metadata": {},
   "outputs": [],
   "source": [
    " df2 = spark.createDataFrame(data2, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fab32f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+-----+------+------+\n",
      "|firstname|lastname|lastname|   id|gender|salary|\n",
      "+---------+--------+--------+-----+------+------+\n",
      "|    James|        |   Smith|36636|     M|  3000|\n",
      "|  Michael|    Rose|        |40288|     M|  4000|\n",
      "|   Robert|        |Williams|42114|     M|  4000|\n",
      "|    Maria|    Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|    Mary|   Brown|     |     F|    -1|\n",
      "+---------+--------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a36b48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data frame from csv\n",
    "df3 = spark.read.csv(\"F:/Data science/train_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5728dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+\n",
      "|  _c0|  _c1| _c2|\n",
      "+-----+-----+----+\n",
      "|train|speed|city|\n",
      "|  341|    4|   a|\n",
      "|  354|   53|   b|\n",
      "| 6425|   56|   r|\n",
      "|    3|  474|   g|\n",
      "| 4734|   35|   f|\n",
      "|  563|  356|   d|\n",
      "|    4|   43|   s|\n",
      "+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51016060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create\n",
    "df4 = spark.read.text(\"C:/Users/W10/Desktop/salary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f1bce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|+91 in mobile number|\n",
      "|       Mumbai, India|\n",
      "|                    |\n",
      "|                    |\n",
      "|                    |\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1e94495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = spark.read.json(\"C:/Users/W10/Desktop/sparkTxt/sample2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0373b2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----+\n",
      "|     _corrupt_record|number|type|\n",
      "+--------------------+------+----+\n",
      "|                   {|  null|null|\n",
      "|   \"firstName\": \"...|  null|null|\n",
      "|   \"lastName\": \"J...|  null|null|\n",
      "|   \"gender\": \"male\",|  null|null|\n",
      "|          \"age\": 28,|  null|null|\n",
      "+--------------------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed0d5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyrdd = spark.sparkContext.emptyRDD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cd8a7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emptyrdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcb3c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasDF = df5.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a97ba19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pandasDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c157f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1525fe08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DOT595I:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x281b38a4be0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27948e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark.sparkContext.parallelize(range(20),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8553b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bea13dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd1.filter(lambda x: x<15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e06f54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd2.filter(lambda x: x+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "508d4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd3.filter(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d84f0116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RDD.toDebugString of PythonRDD[57] at RDD at PythonRDD.scala:53>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5956cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------\n",
      " _corrupt_record | {                              \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 1-----------------------------------------\n",
      " _corrupt_record |    \"firstName\": \"Joe\",         \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 2-----------------------------------------\n",
      " _corrupt_record |    \"lastName\": \"Jackson\",      \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 3-----------------------------------------\n",
      " _corrupt_record |    \"gender\": \"male\",           \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 4-----------------------------------------\n",
      " _corrupt_record |    \"age\": 28,                  \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 5-----------------------------------------\n",
      " _corrupt_record |    \"address\": {                \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 6-----------------------------------------\n",
      " _corrupt_record |        \"streetAddress\": \"101\", \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 7-----------------------------------------\n",
      " _corrupt_record |        \"city\": \"San Diego\",    \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 8-----------------------------------------\n",
      " _corrupt_record |        \"state\": \"CA\"           \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 9-----------------------------------------\n",
      " _corrupt_record |    },                          \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 10----------------------------------------\n",
      " _corrupt_record |    \"phoneNumbers\": [           \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 11----------------------------------------\n",
      " _corrupt_record | null                           \n",
      " number          | 7349282382                     \n",
      " type            | home                           \n",
      "-RECORD 12----------------------------------------\n",
      " _corrupt_record |    ]                           \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "-RECORD 13----------------------------------------\n",
      " _corrupt_record | }                              \n",
      " number          | null                           \n",
      " type            | null                           \n",
      "\n",
      "+--------------------+----------+----+\n",
      "|     _corrupt_record|    number|type|\n",
      "+--------------------+----------+----+\n",
      "|                   {|      null|null|\n",
      "|   \"firstName\": \"...|      null|null|\n",
      "|   \"lastName\": \"J...|      null|null|\n",
      "|   \"gender\": \"male\",|      null|null|\n",
      "|          \"age\": 28,|      null|null|\n",
      "|        \"address\": {|      null|null|\n",
      "|       \"streetAdd...|      null|null|\n",
      "|       \"city\": \"S...|      null|null|\n",
      "|       \"state\": \"CA\"|      null|null|\n",
      "|                  },|      null|null|\n",
      "|   \"phoneNumbers\": [|      null|null|\n",
      "|                null|7349282382|home|\n",
      "|                   ]|      null|null|\n",
      "|                   }|      null|null|\n",
      "+--------------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(n=20, truncate=False, vertical=True)\n",
    "df5.show(n=20, truncate=True, vertical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "450b5bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jack 40\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "row = Row(name=\"jack\",marks=40)\n",
    "print(row[0],str(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f2b4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "Class = Row(\"name\",\"age\")\n",
    "c1 = Class(\"jack\",20)\n",
    "c2 = Class(\"mack\",23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3937c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jack\n"
     ]
    }
   ],
   "source": [
    "print(c1.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93298b7",
   "metadata": {},
   "source": [
    "## select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdfcf003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----+\n",
      "|     _corrupt_record|    number|type|\n",
      "+--------------------+----------+----+\n",
      "|                   {|      null|null|\n",
      "|   \"firstName\": \"...|      null|null|\n",
      "|   \"lastName\": \"J...|      null|null|\n",
      "|   \"gender\": \"male\",|      null|null|\n",
      "|          \"age\": 28,|      null|null|\n",
      "|        \"address\": {|      null|null|\n",
      "|       \"streetAdd...|      null|null|\n",
      "|       \"city\": \"S...|      null|null|\n",
      "|       \"state\": \"CA\"|      null|null|\n",
      "|                  },|      null|null|\n",
      "|   \"phoneNumbers\": [|      null|null|\n",
      "|                null|7349282382|home|\n",
      "|                   ]|      null|null|\n",
      "|                   }|      null|null|\n",
      "+--------------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f59c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d30fa1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+-----+\n",
      "|firstname|lastname|salary| dept|\n",
      "+---------+--------+------+-----+\n",
      "|     jack|  futane| 29000|   cs|\n",
      "|    jack1| futane1| 23000|  ext|\n",
      "|    jack2| futane2| 24000| mech|\n",
      "|    jack3| futane3| 25000|  ext|\n",
      "|    jack4| futane4| 26000|   cs|\n",
      "|    jack5| futane5| 36000|civil|\n",
      "+---------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6 = spark.createDataFrame(\n",
    "    [('jack','futane',29000,'cs'),('jack1','futane1',23000,'ext'),('jack2','futane2',24000,'mech'),\n",
    "     ('jack3','futane3',25000,'ext'),('jack4','futane4',26000,'cs'),('jack5','futane5',36000,'civil')]\n",
    "    ,['firstname','lastname',\"salary\",\"dept\"])\n",
    "\n",
    "# df6.select(\"firstname\",\"lastname\").show()\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# df6.select(col('firstname'),col('lastname')).show()\n",
    "\n",
    "# df6.select(df6['firstname'],df6['lastname']).show()\n",
    "\n",
    "df6.select(\"*\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "854755e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|     jack|  futane|\n",
      "|    jack1| futane1|\n",
      "|    jack2| futane2|\n",
      "|    jack3| futane3|\n",
      "|    jack4| futane4|\n",
      "|    jack5| futane5|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.select(df6.columns[:2]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6add9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+-----+\n",
      "|firstname|lastname|salary| dept|\n",
      "+---------+--------+------+-----+\n",
      "|     jack|  futane| 29000|   cs|\n",
      "|    jack1| futane1| 23000|  ext|\n",
      "|    jack2| futane2| 24000| mech|\n",
      "|    jack3| futane3| 25000|  ext|\n",
      "|    jack4| futane4| 26000|   cs|\n",
      "|    jack5| futane5| 36000|civil|\n",
      "+---------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.withColumn('salary',col('salary').cast(\"Integer\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "183a82fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname| salary| dept|\n",
      "+---------+--------+-------+-----+\n",
      "|     jack|  futane|2900000|   cs|\n",
      "|    jack1| futane1|2300000|  ext|\n",
      "|    jack2| futane2|2400000| mech|\n",
      "|    jack3| futane3|2500000|  ext|\n",
      "|    jack4| futane4|2600000|   cs|\n",
      "|    jack5| futane5|3600000|civil|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.withColumn('salary',col(\"salary\")*100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a43ee560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.withColumn('salary',col('salary').alias(\"jack\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "658ccbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+-----+\n",
      "|firstname|lastname|salary| dept|\n",
      "+---------+--------+------+-----+\n",
      "|     jack|  futane| 29000|   cs|\n",
      "|    jack1| futane1| 23000|  ext|\n",
      "|    jack2| futane2| 24000| mech|\n",
      "|    jack3| futane3| 25000|  ext|\n",
      "|    jack4| futane4| 26000|   cs|\n",
      "|    jack5| futane5| 36000|civil|\n",
      "+---------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7ae4eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+-----+\n",
      "|firstname|lastname|salary| dept|\n",
      "+---------+--------+------+-----+\n",
      "|    jack1| futane1| 23000|  ext|\n",
      "|    jack2| futane2| 24000| mech|\n",
      "|    jack3| futane3| 25000|  ext|\n",
      "|    jack4| futane4| 26000|   cs|\n",
      "|    jack5| futane5| 36000|civil|\n",
      "+---------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.filter(df6.firstname!='jack').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1de6a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+----+\n",
      "|firstname|lastname|salary|dept|\n",
      "+---------+--------+------+----+\n",
      "|     jack|  futane| 29000|  cs|\n",
      "+---------+--------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.filter(~(df6.firstname=='jack'))\n",
    "df6.filter(col('firstname')=='jack').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d799fb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+----+\n",
      "|firstname|lastname|salary|dept|\n",
      "+---------+--------+------+----+\n",
      "|     jack|  futane| 29000|  cs|\n",
      "+---------+--------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.where(\"firstname == 'jack'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "076ec8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|lastname|salary| dept|\n",
      "+--------+------+-----+\n",
      "|  futane| 29000|   cs|\n",
      "| futane1| 23000|  ext|\n",
      "| futane2| 24000| mech|\n",
      "| futane3| 25000|  ext|\n",
      "| futane4| 26000|   cs|\n",
      "| futane5| 36000|civil|\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7.drop(\"firstname\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e0b306d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.select('firstname').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "824e2eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+-----+\n",
      "|firstname|lastname|salary| dept|\n",
      "+---------+--------+------+-----+\n",
      "|    jack1| futane1| 23000|  ext|\n",
      "|    jack2| futane2| 24000| mech|\n",
      "|    jack3| futane3| 25000|  ext|\n",
      "|    jack4| futane4| 26000|   cs|\n",
      "|     jack|  futane| 29000|   cs|\n",
      "|    jack5| futane5| 36000|civil|\n",
      "+---------+--------+------+-----+\n",
      "\n",
      "+---------+--------+------+-----+\n",
      "|firstname|lastname|salary| dept|\n",
      "+---------+--------+------+-----+\n",
      "|    jack1| futane1| 23000|  ext|\n",
      "|    jack2| futane2| 24000| mech|\n",
      "|    jack3| futane3| 25000|  ext|\n",
      "|    jack4| futane4| 26000|   cs|\n",
      "|     jack|  futane| 29000|   cs|\n",
      "|    jack5| futane5| 36000|civil|\n",
      "+---------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.sort(\"salary\").show()\n",
    "df6.orderBy(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79f3ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.groupBy(\"dept\").sum(\"salary\").alias(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18052fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e14f8501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| dept|salary|\n",
      "+-----+------+\n",
      "|  ext| 48000|\n",
      "|   cs| 55000|\n",
      "|civil| 36000|\n",
      "| mech| 24000|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7.select(col(\"dept\").alias('dept'), col(\"sum(salary)\").alias(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f9cdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
    "  ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
    "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(emp,empColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1cd07377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54e968e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept = [(\"Finance\",10), \\\n",
    "    (\"Marketing\",20), \\\n",
    "    (\"Sales\",30), \\\n",
    "    (\"IT\",40) \\\n",
    "  ]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "\n",
    "deptDF = spark.createDataFrame(dept,deptColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "914be6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deptDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a8c9a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6a00b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DOT595I:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x281b38a4be0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebab93aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2b717b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertString(x):\n",
    "    # print(x)\n",
    "    arr = x.split(\" \")\n",
    "    result = \"\"\n",
    "    for i in arr:\n",
    "        result = result + str(i[0].upper())+\"\"+ str(i[1:len(i)+1])+\" \"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b91934ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack Rao Mitali Raj And Me \n"
     ]
    }
   ],
   "source": [
    "print(convertString(\"jack rao mitali raj and me\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd374f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "temprdd = spark.sparkContext.parallelize(['jack','jack2','jack3','jack4','jack5','jack6','jack7','jack8',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab3e0a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RDD.toDebugString of ParallelCollectionRDD[145] at readRDDFromFile at PythonRDD.scala:262>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temprdd.toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d923a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jack', 1),\n",
       " ('jack2', 1),\n",
       " ('jack3', 1),\n",
       " ('jack4', 1),\n",
       " ('jack5', 1),\n",
       " ('jack6', 1),\n",
       " ('jack7', 1),\n",
       " ('jack8', 1)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temprdd.map(lambda x: (x,1)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "babbca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temprdd2 = spark.sparkContext.parallelize([('jack',22),('jack1',212),('jack2',222),('jack3',232),('jack4',242),('jack5',252)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96956e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "listt = temprdd2.flatMap(lambda x : x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0fd3291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jack',\n",
       " 22,\n",
       " 'jack1',\n",
       " 212,\n",
       " 'jack2',\n",
       " 222,\n",
       " 'jack3',\n",
       " 232,\n",
       " 'jack4',\n",
       " 242,\n",
       " 'jack5',\n",
       " 252]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listt.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "606dcff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b58490eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temprdd3 =spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aabc4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temprdd3.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18e62e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.range(0,100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d99d7576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  2|\n",
      "|  4|\n",
      "|  6|\n",
      "|  8|\n",
      "| 10|\n",
      "| 12|\n",
      "| 14|\n",
      "| 16|\n",
      "| 18|\n",
      "| 20|\n",
      "| 22|\n",
      "| 24|\n",
      "| 26|\n",
      "| 28|\n",
      "| 30|\n",
      "| 32|\n",
      "| 34|\n",
      "| 36|\n",
      "| 38|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2fb2d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "| 10|\n",
      "| 12|\n",
      "| 14|\n",
      "| 20|\n",
      "| 22|\n",
      "| 24|\n",
      "| 24|\n",
      "| 24|\n",
      "| 26|\n",
      "| 28|\n",
      "| 36|\n",
      "| 42|\n",
      "| 44|\n",
      "| 48|\n",
      "| 56|\n",
      "| 62|\n",
      "| 64|\n",
      "| 68|\n",
      "| 70|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.sample(True,0.6,123).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9fd7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.createDataFrame([('jack','java',22),('jack1','java1',212),('jack2','java2',222),('jack3','java3',232),\n",
    "                            ('jack','NULL',22),('jack1','null',212),('null','java2',222)], \n",
    "                           ['name','languages','age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "014158b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---+\n",
      "| name|languages|age|\n",
      "+-----+---------+---+\n",
      "| jack|     java| 22|\n",
      "|jack1|    java1|212|\n",
      "|jack2|    java2|222|\n",
      "|jack3|    java3|232|\n",
      "| jack|     NULL| 22|\n",
      "|jack1|     null|212|\n",
      "| null|    java2|222|\n",
      "+-----+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.na.fill(value=\" \", subset=[\"languages\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10edf976",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
    "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n",
    "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
    "\n",
    "columns= [\"Product\",\"Amount\",\"Country\"]\n",
    "dfnew3 = spark.createDataFrame(data = data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83238e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b57942d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfna = spark.read.options(header='true', inferSchema='true') \\\n",
    "          .csv(\"C:/Users/W10/Desktop/sparkTxt/rating2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2dd26c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+---------+\n",
      "|userId|movieId|rating| timestamp|ratingStr|\n",
      "+------+-------+------+----------+---------+\n",
      "|     1|     39|   2.6|1260759144|      one|\n",
      "|     1|     38|   2.7|      null|      two|\n",
      "|     1|   null|   2.7|1260759140|    three|\n",
      "|     0|     36|   3.8|1260759149|     null|\n",
      "|     1|     35|   4.9|1260759148|     five|\n",
      "|     1|   null|   5.0|      null|     null|\n",
      "|     0|     33|   3.1|1260759146|    seven|\n",
      "|     1|     32|  null|1260759145|    eight|\n",
      "+------+-------+------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfna.na.fill(value=0, subset=['userId']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f80c75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+---------+\n",
      "|userId|movieId|rating| timestamp|ratingStr|\n",
      "+------+-------+------+----------+---------+\n",
      "|     1|     39|   2.6|1260759144|      one|\n",
      "|     1|     38|   2.7|      null|      two|\n",
      "|     1|   null|   2.7|1260759140|    three|\n",
      "|  null|     36|   3.8|1260759149|     null|\n",
      "|     1|     35|   4.9|1260759148|     five|\n",
      "|     1|   null|   5.0|      null|     null|\n",
      "|  null|     33|   3.1|1260759146|    seven|\n",
      "|     1|     32|  null|1260759145|    eight|\n",
      "+------+-------+------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfna.fillna(value=\"\", subset=['timestamp']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "796d6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
    "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n",
    "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
    "\n",
    "columns= [\"Product\",\"Amount\",\"Country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "975024a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpivot = spark.createDataFrame(data = data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2260013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-------+------+\n",
      "|Country|Banana|Beans|Carrots|Orange|\n",
      "+-------+------+-----+-------+------+\n",
      "|  China|   400| 1500|   1200|  4000|\n",
      "|    USA|  1000| 1600|   1500|  4000|\n",
      "| Mexico|  null| 2000|   null|  null|\n",
      "| Canada|  2000| null|   2000|  null|\n",
      "+-------+------+-----+-------+------+\n",
      "\n",
      "+-------+------+-------+\n",
      "|Product|Amount|Country|\n",
      "+-------+------+-------+\n",
      "| Banana|  1000|    USA|\n",
      "|Carrots|  1500|    USA|\n",
      "|  Beans|  1600|    USA|\n",
      "| Orange|  2000|    USA|\n",
      "| Orange|  2000|    USA|\n",
      "| Banana|   400|  China|\n",
      "|Carrots|  1200|  China|\n",
      "|  Beans|  1500|  China|\n",
      "| Orange|  4000|  China|\n",
      "| Banana|  2000| Canada|\n",
      "|Carrots|  2000| Canada|\n",
      "|  Beans|  2000| Mexico|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpivot.groupBy('Country').pivot('Product').sum('Amount').show()\n",
    "dfpivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb1f0618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----+\n",
      "|     _corrupt_record|    number|type|\n",
      "+--------------------+----------+----+\n",
      "|                   {|      null|null|\n",
      "|   \"firstName\": \"...|      null|null|\n",
      "|   \"lastName\": \"J...|      null|null|\n",
      "|   \"gender\": \"male\",|      null|null|\n",
      "|          \"age\": 28,|      null|null|\n",
      "|        \"address\": {|      null|null|\n",
      "|       \"streetAdd...|      null|null|\n",
      "|       \"city\": \"S...|      null|null|\n",
      "|       \"state\": \"CA\"|      null|null|\n",
      "|                  },|      null|null|\n",
      "|   \"phoneNumbers\": [|      null|null|\n",
      "|                null|7349282382|home|\n",
      "|                   ]|      null|null|\n",
      "|                   }|      null|null|\n",
      "+--------------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56d667c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c31826e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
    "broadcastStates = spark.sparkContext.broadcast(states)\n",
    "\n",
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "def state_convert(code):\n",
    "    return broadcastStates.value[code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3bc148c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('James', 'Smith', 'USA', 'California'),\n",
       " ('Michael', 'Rose', 'USA', 'New York'),\n",
       " ('Robert', 'Williams', 'USA', 'California'),\n",
       " ('Maria', 'Jones', 'USA', 'Florida')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "db66e3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcastStates.value['NY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3dbcb901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f9015d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                        |\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|+91 in mobile number                                                                                         |\n",
      "|Mumbai, India                                                                                                |\n",
      "|                                                                                                             |\n",
      "|                                                                                                             |\n",
      "|                                                                                                             |\n",
      "|Working as Data Engineer with 1.5+ years of experience in building data-intensive applications.              |\n",
      "|Collecting and processing data creating scalable data pipelines using ELT and creating schemas to store data.|\n",
      "|Creating efficient data models and creating analysis and reports using data models.                          |\n",
      "|Data Warehousing, Data Modeling, and Data Visualization                                                      |\n",
      "|                                                                                                             |\n",
      "|Experience                                                                                                   |\n",
      "|Data warehousing, Data Modeling, Data Visualization                                                          |\n",
      "|                                                                                                             |\n",
      "|Programming Languages                                                                                        |\n",
      "|SQL, Python, Java, Javascript                                                                                |\n",
      "|                                                                                                             |\n",
      "|Skills                                                                                                       |\n",
      "|Business Intelligence                                                                                        |\n",
      "|Data Warehouse                                                                                               |\n",
      "|Analytics                                                                                                    |\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2be2c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = Row('name','age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f350273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = row(\"jack\",22)\n",
    "r2 = row(\"mack\",23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a9c339e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jack'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6201f403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----+\n",
      "|     _corrupt_record|    number|type|\n",
      "+--------------------+----------+----+\n",
      "|                   {|      null|null|\n",
      "|   \"firstName\": \"...|      null|null|\n",
      "|   \"lastName\": \"J...|      null|null|\n",
      "|   \"gender\": \"male\",|      null|null|\n",
      "|          \"age\": 28,|      null|null|\n",
      "|        \"address\": {|      null|null|\n",
      "|       \"streetAdd...|      null|null|\n",
      "|       \"city\": \"S...|      null|null|\n",
      "|       \"state\": \"CA\"|      null|null|\n",
      "|                  },|      null|null|\n",
      "|   \"phoneNumbers\": [|      null|null|\n",
      "|                null|7349282382|home|\n",
      "|                   ]|      null|null|\n",
      "|                   }|      null|null|\n",
      "+--------------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3d111819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|+91 in mobile number|\n",
      "|       Mumbai, India|\n",
      "|                    |\n",
      "|                    |\n",
      "|                    |\n",
      "|Working as Data E...|\n",
      "|Collecting and pr...|\n",
      "|Creating efficien...|\n",
      "|Data Warehousing,...|\n",
      "|                    |\n",
      "|          Experience|\n",
      "|Data warehousing,...|\n",
      "|                    |\n",
      "|Programming Langu...|\n",
      "|SQL, Python, Java...|\n",
      "|                    |\n",
      "|              Skills|\n",
      "|Business Intellig...|\n",
      "|      Data Warehouse|\n",
      "|           Analytics|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f3040e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----+\n",
      "|     _corrupt_record|    number|type|\n",
      "+--------------------+----------+----+\n",
      "|                   {|      null|null|\n",
      "|   \"firstName\": \"...|      null|null|\n",
      "|   \"lastName\": \"J...|      null|null|\n",
      "|   \"gender\": \"male\",|      null|null|\n",
      "|          \"age\": 28,|      null|null|\n",
      "|        \"address\": {|      null|null|\n",
      "|       \"streetAdd...|      null|null|\n",
      "|       \"city\": \"S...|      null|null|\n",
      "|       \"state\": \"CA\"|      null|null|\n",
      "|                  },|      null|null|\n",
      "|   \"phoneNumbers\": [|      null|null|\n",
      "|                null|7349282382|home|\n",
      "|                   ]|      null|null|\n",
      "|                   }|      null|null|\n",
      "+--------------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf027aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bea877dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|    _1|    _2|\n",
      "+------+------+\n",
      "|  Java| 20000|\n",
      "|Python|100000|\n",
      "| Scala|  3000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d38bb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "df915224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    dateee|\n",
      "+----------+\n",
      "|2022-08-17|\n",
      "+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date().alias('dateee')).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8ddee16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|    _1|\n",
      "+------+\n",
      "|  Java|\n",
      "|Python|\n",
      "| Scala|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('_1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "984b2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[[\"1\",\"2020-02-01\"],[\"2\",\"2019-03-01\"],[\"3\",\"2021-03-01\"]]\n",
    "df2=spark.createDataFrame(data,[\"id\",\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d350058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|     input|\n",
      "+---+----------+\n",
      "|  1|2020-02-01|\n",
      "|  2|2019-03-01|\n",
      "|  3|2021-03-01|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d001d178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_date()|\n",
      "+--------------+\n",
      "|    2022-08-17|\n",
      "+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(current_date()).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b855ec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|     input|date_format|\n",
      "+----------+-----------+\n",
      "|2020-02-01| 02-01-2020|\n",
      "|2019-03-01| 03-01-2019|\n",
      "|2021-03-01| 03-01-2021|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(col(\"input\"), \n",
    "    date_format(col(\"input\"), \"MM-dd-yyyy\").alias(\"date_format\") \n",
    "  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11545b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bv = spark.sparkContext.broadcast([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "34d7b6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55049b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bv.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e74087be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, languages: string, age: bigint]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d4a0686f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='jack', languages='java', age=22),\n",
       " Row(name='jack1', languages='java1', age=212),\n",
       " Row(name='jack2', languages='java2', age=222),\n",
       " Row(name='jack3', languages='java3', age=232),\n",
       " Row(name='jack', languages='NULL', age=22),\n",
       " Row(name='jack1', languages='null', age=212),\n",
       " Row(name='null', languages='java2', age=222)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eb77ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---+\n",
      "| name|languages|age|\n",
      "+-----+---------+---+\n",
      "| jack|     java| 22|\n",
      "|jack1|    java1|212|\n",
      "|jack2|    java2|222|\n",
      "|jack3|    java3|232|\n",
      "| jack|     NULL| 22|\n",
      "|jack1|     null|212|\n",
      "| null|    java2|222|\n",
      "+-----+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7bc126fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78d6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
